"""
LOTOBET AI v1.0
Tool ph√¢n t√≠ch v√† d·ª± ƒëo√°n s·ªë x·ªï s·ªë
Author: Senior Python Developer + Data Analyst
Version: 1.0
"""

import streamlit as st
import pandas as pd
import numpy as np
import requests
import io
import re
from datetime import datetime
from collections import Counter, defaultdict
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# ==================== CONFIGURATION ====================
st.set_page_config(
    page_title="LOTOBET AI v1.0",
    page_icon="üéØ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== INITIALIZATION ====================
if 'data' not in st.session_state:
    st.session_state.data = pd.DataFrame(columns=['number'])
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None
if 'raw_data' not in st.session_state:
    st.session_state.raw_data = ""

# ==================== UTILITY FUNCTIONS ====================
def clean_number_string(num_str):
    """L√†m s·∫°ch chu·ªói s·ªë, ch·ªâ gi·ªØ l·∫°i k√Ω t·ª± s·ªë"""
    if pd.isna(num_str):
        return ""
    # Chuy·ªÉn sang string v√† lo·∫°i b·ªè m·ªçi k√Ω t·ª± kh√¥ng ph·∫£i s·ªë
    cleaned = re.sub(r'[^\d]', '', str(num_str))
    return cleaned

def validate_lottery_number(num_str):
    """Ki·ªÉm tra s·ªë h·ª£p l·ªá (ƒë√∫ng 5 ch·ªØ s·ªë)"""
    cleaned = clean_number_string(num_str)
    return len(cleaned) == 5

def parse_input_data(input_text):
    """Ph√¢n t√≠ch d·ªØ li·ªáu ƒë·∫ßu v√†o t·ª´ nhi·ªÅu ƒë·ªãnh d·∫°ng"""
    numbers = []
    lines = input_text.strip().split('\n')
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # T√°ch c√°c s·ªë tr√™n c√πng m·ªôt d√≤ng (ph√¢n c√°ch b·ªüi d·∫•u c√°ch, d·∫•u ph·∫©y, tab)
        line_parts = re.split(r'[\s,\t]+', line)
        
        for part in line_parts:
            part = part.strip()
            if part:
                cleaned = clean_number_string(part)
                if len(cleaned) == 5:
                    numbers.append(cleaned)
    
    return list(set(numbers))  # Lo·∫°i b·ªè tr√πng l·∫∑p

def download_sample_data():
    """T·∫£i d·ªØ li·ªáu m·∫´u t·ª´ c√°c ngu·ªìn"""
    sample_data = """12345
67890
54321
09876
13579
24680
11223
44556
77889
99001"""
    return sample_data

# ==================== CORE ALGORITHMS ====================
class LotteryAnalyzer:
    """L·ªõp ch·ª©a thu·∫≠t to√°n ph√¢n t√≠ch s·ªë"""
    
    def __init__(self, data):
        self.data = data
        self.numbers = data['number'].tolist()
        self.all_digits = []
        self._extract_digits()
    
    def _extract_digits(self):
        """Tr√≠ch xu·∫•t t·∫•t c·∫£ c√°c ch·ªØ s·ªë t·ª´ d·ªØ li·ªáu"""
        for num in self.numbers:
            self.all_digits.extend(list(num))
    
    def frequency_analysis(self):
        """Ph√¢n t√≠ch t·∫ßn su·∫•t xu·∫•t hi·ªán c·ªßa c√°c s·ªë"""
        freq = Counter(self.all_digits)
        total_digits = len(self.all_digits)
        
        results = {}
        for digit in '0123456789':
            count = freq.get(digit, 0)
            results[digit] = {
                'count': count,
                'frequency': count / total_digits if total_digits > 0 else 0
            }
        return results
    
    def delay_analysis(self):
        """Ph√¢n t√≠ch ƒë·ªô tr·ªÖ gi·ªØa c√°c l·∫ßn xu·∫•t hi·ªán"""
        digit_positions = {digit: [] for digit in '0123456789'}
        
        for idx, num in enumerate(self.numbers):
            for pos, digit in enumerate(num):
                digit_positions[digit].append(idx)
        
        delay_results = {}
        for digit in '0123456789':
            positions = digit_positions[digit]
            if len(positions) < 2:
                delay_results[digit] = {'avg_delay': 999, 'max_delay': 999}
                continue
            
            delays = [positions[i+1] - positions[i] for i in range(len(positions)-1)]
            delay_results[digit] = {
                'avg_delay': np.mean(delays) if delays else 999,
                'max_delay': max(delays) if delays else 999
            }
        
        return delay_results
    
    def cycle_analysis(self):
        """Ph√¢n t√≠ch chu k·ª≥ xu·∫•t hi·ªán"""
        digit_history = {digit: [] for digit in '0123456789'}
        
        for num in self.numbers:
            for digit in '0123456789':
                digit_history[digit].append(1 if digit in num else 0)
        
        cycle_results = {}
        for digit in '0123456789':
            history = digit_history[digit]
            if sum(history) < 3:
                cycle_results[digit] = {'cycle_strength': 0}
                continue
            
            # T√¨m chu k·ª≥ ng·∫Øn h·∫°n (2-5 k·ª≥)
            cycles = []
            for cycle_len in range(2, 6):
                pattern_score = 0
                for i in range(len(history) - cycle_len):
                    pattern = history[i:i+cycle_len]
                    # Ki·ªÉm tra l·∫∑p l·∫°i
                    repeat_count = 0
                    for j in range(i+cycle_len, len(history)-cycle_len, cycle_len):
                        if history[j:j+cycle_len] == pattern:
                            repeat_count += 1
                    if repeat_count > 0:
                        pattern_score += repeat_count
                
                cycles.append({'length': cycle_len, 'score': pattern_score})
            
            # T√¨m chu k·ª≥ m·∫°nh nh·∫•t
            best_cycle = max(cycles, key=lambda x: x['score'])
            cycle_results[digit] = {
                'cycle_strength': best_cycle['score'],
                'cycle_length': best_cycle['length']
            }
        
        return cycle_results
    
    def cooccurrence_analysis(self):
        """Ph√¢n t√≠ch ƒë·ªìng xu·∫•t hi·ªán gi·ªØa c√°c s·ªë"""
        cooccurrence = defaultdict(lambda: defaultdict(int))
        
        for num in self.numbers:
            digits_in_num = set(num)
            for d1 in digits_in_num:
                for d2 in digits_in_num:
                    if d1 != d2:
                        cooccurrence[d1][d2] += 1
        
        # T√≠nh ƒëi·ªÉm ƒë·ªìng xu·∫•t hi·ªán
        cooccurrence_scores = {}
        for digit in '0123456789':
            total_pairs = sum(cooccurrence[digit].values())
            unique_partners = len(cooccurrence[digit])
            score = (total_pairs * 0.7) + (unique_partners * 0.3)
            cooccurrence_scores[digit] = score
        
        return cooccurrence_scores
    
    def pattern_analysis(self):
        """Ph√¢n t√≠ch pattern ng·∫Øn h·∫°n"""
        pattern_scores = {digit: 0 for digit in '0123456789'}
        
        if len(self.numbers) < 5:
            return pattern_scores
        
        # Ph√¢n t√≠ch trend 5 k·ª≥ g·∫ßn nh·∫•t
        recent_numbers = self.numbers[-5:]
        recent_digits = []
        for num in recent_numbers:
            recent_digits.extend(list(num))
        
        recent_counter = Counter(recent_digits)
        total_recent = len(recent_digits)
        
        for digit in '0123456789':
            if total_recent > 0:
                recent_freq = recent_counter.get(digit, 0) / total_recent
                # Trend tƒÉng/gi·∫£m
                trend_score = recent_freq * 1.5  # ∆Øu ti√™n s·ªë xu·∫•t hi·ªán g·∫ßn ƒë√¢y
                pattern_scores[digit] = trend_score
        
        return pattern_scores
    
    def entropy_analysis(self):
        """Ph√¢n t√≠ch entropy - ƒë·ªô b·∫•t ƒë·ªãnh"""
        digit_probabilities = {}
        total_digits = len(self.all_digits)
        
        for digit in '0123456789':
            count = self.all_digits.count(digit)
            prob = count / total_digits if total_digits > 0 else 0
            digit_probabilities[digit] = prob
        
        # T√≠nh entropy cho t·ª´ng s·ªë
        entropy_scores = {}
        for digit in '0123456789':
            p = digit_probabilities[digit]
            if p > 0:
                entropy = -p * np.log2(p)
            else:
                entropy = 0
            entropy_scores[digit] = entropy
        
        return entropy_scores
    
    def noise_reduction_analysis(self):
        """Ph√¢n t√≠ch lo·∫°i nhi·ªÖu v√† bias"""
        position_counts = {digit: [0, 0, 0, 0, 0] for digit in '0123456789'}
        
        for num in self.numbers:
            for pos, digit in enumerate(num):
                position_counts[digit][pos] += 1
        
        # Ph√°t hi·ªán bias theo v·ªã tr√≠
        bias_scores = {}
        for digit in '0123456789':
            counts = position_counts[digit]
            total = sum(counts)
            if total == 0:
                bias_scores[digit] = 1.0  # Kh√¥ng bias
                continue
            
            # T√≠nh ƒë·ªô ph√¢n t√°n (variance)
            mean = total / 5
            variance = sum([(c - mean) ** 2 for c in counts]) / 5
            std_dev = np.sqrt(variance)
            
            # Score c√†ng cao c√†ng √≠t bias
            bias_score = 1.0 / (1.0 + std_dev)
            bias_scores[digit] = bias_score
        
        return bias_scores
    
    def analyze_all(self):
        """Ch·∫°y t·∫•t c·∫£ thu·∫≠t to√°n v√† t·ªïng h·ª£p k·∫øt qu·∫£"""
        if len(self.numbers) < 3:
            st.warning("C·∫ßn √≠t nh·∫•t 3 s·ªë ƒë·ªÉ ph√¢n t√≠ch hi·ªáu qu·∫£")
            return None
        
        # Ch·∫°y 7 thu·∫≠t to√°n
        results = {}
        
        # 1. T·∫ßn su·∫•t xu·∫•t hi·ªán
        freq = self.frequency_analysis()
        
        # 2. ƒê·ªô tr·ªÖ
        delay = self.delay_analysis()
        
        # 3. Chu k·ª≥
        cycle = self.cycle_analysis()
        
        # 4. ƒê·ªìng xu·∫•t hi·ªán
        cooccurrence = self.cooccurrence_analysis()
        
        # 5. Pattern ng·∫Øn h·∫°n
        pattern = self.pattern_analysis()
        
        # 6. Entropy
        entropy = self.entropy_analysis()
        
        # 7. Lo·∫°i nhi·ªÖu
        noise = self.noise_reduction_analysis()
        
        # T√≠nh ƒëi·ªÉm t·ªïng h·ª£p cho t·ª´ng s·ªë
        for digit in '0123456789':
            # Tr·ªçng s·ªë cho t·ª´ng thu·∫≠t to√°n
            weights = {
                'frequency': 0.25,      # T·∫ßn su·∫•t: quan tr·ªçng nh·∫•t
                'delay': 0.15,          # ƒê·ªô tr·ªÖ
                'cycle': 0.15,          # Chu k·ª≥
                'cooccurrence': 0.10,   # ƒê·ªìng xu·∫•t hi·ªán
                'pattern': 0.15,        # Pattern ng·∫Øn h·∫°n
                'entropy': 0.10,        # Entropy
                'noise': 0.10           # Lo·∫°i nhi·ªÖu
            }
            
            # Chu·∫©n h√≥a ƒëi·ªÉm
            freq_score = freq[digit]['frequency']
            
            # ƒê·ªô tr·ªÖ: tr·ªÖ c√†ng l√¢u ƒëi·ªÉm c√†ng cao (c√†ng c√≥ kh·∫£ nƒÉng xu·∫•t hi·ªán)
            delay_score = 1.0 / (1.0 + delay[digit]['avg_delay'] / 10)
            
            # Chu k·ª≥
            cycle_score = min(cycle[digit]['cycle_strength'] / 5, 1.0)
            
            # ƒê·ªìng xu·∫•t hi·ªán: chu·∫©n h√≥a
            max_cooccur = max(cooccurrence.values()) if cooccurrence.values() else 1
            cooccur_score = cooccurrence[digit] / max_cooccur if max_cooccur > 0 else 0
            
            # Pattern
            pattern_score = pattern[digit]
            
            # Entropy: chu·∫©n h√≥a
            max_entropy = max(entropy.values()) if entropy.values() else 1
            entropy_score = entropy[digit] / max_entropy if max_entropy > 0 else 0
            
            # Lo·∫°i nhi·ªÖu
            noise_score = noise[digit]
            
            # T√≠nh t·ªïng ƒëi·ªÉm c√≥ tr·ªçng s·ªë
            total_score = (
                freq_score * weights['frequency'] +
                delay_score * weights['delay'] +
                cycle_score * weights['cycle'] +
                cooccur_score * weights['cooccurrence'] +
                pattern_score * weights['pattern'] +
                entropy_score * weights['entropy'] +
                noise_score * weights['noise']
            )
            
            # Chuy·ªÉn th√†nh ph·∫ßn trƒÉm
            percentage = min(total_score * 100, 99.9)
            
            # Khuy·∫øn ngh·ªã
            recommendation = "ƒê√ÅNH" if percentage > 50 else "KH√îNG"
            
            results[digit] = {
                'percentage': percentage,
                'recommendation': recommendation,
                'details': {
                    'frequency': freq_score,
                    'delay': delay_score,
                    'cycle': cycle_score,
                    'cooccurrence': cooccur_score,
                    'pattern': pattern_score,
                    'entropy': entropy_score,
                    'noise': noise_score
                }
            }
        
        return results

# ==================== STREAMLIT UI ====================
def main():
    """Giao di·ªán ch√≠nh c·ªßa ·ª©ng d·ª•ng"""
    
    # Header
    st.title("üéØ LOTOBET AI v1.0")
    st.markdown("### Tool Ph√¢n T√≠ch & D·ª± ƒêo√°n S·ªë X·ªï S·ªë")
    st.markdown("---")
    
    # Sidebar
    with st.sidebar:
        st.image("https://img.icons8.com/color/96/000000/lottery.png", width=100)
        st.markdown("### üìä Th·ªëng K√™")
        
        if not st.session_state.data.empty:
            st.info(f"**S·ªë l∆∞·ª£ng d·ªØ li·ªáu:** {len(st.session_state.data)} s·ªë")
            st.info(f"**S·ªë g·∫ßn nh·∫•t:** {st.session_state.data.iloc[-1]['number'] if len(st.session_state.data) > 0 else 'N/A'}")
        else:
            st.warning("Ch∆∞a c√≥ d·ªØ li·ªáu")
        
        st.markdown("---")
        st.markdown("### ‚öôÔ∏è C√†i ƒê·∫∑t")
        auto_analyze = st.checkbox("T·ª± ƒë·ªông ph√¢n t√≠ch", value=True)
        st.markdown("---")
        st.markdown("#### üì± H·ªó Tr·ª£ Mobile")
        st.caption("Tool ƒë∆∞·ª£c t·ªëi ∆∞u cho ƒëi·ªán tho·∫°i")
        st.caption("Phi√™n b·∫£n: 1.0")
    
    # Tabs ch√≠nh
    tab1, tab2, tab3 = st.tabs(["üì• Thu Th·∫≠p D·ªØ Li·ªáu", "‚ö° Ph√¢n T√≠ch Nhanh", "üìä Ph√¢n T√≠ch Chi Ti·∫øt"])
    
    # ========== TAB 1: DATA COLLECTION ==========
    with tab1:
        st.header("üì• Thu Th·∫≠p D·ªØ Li·ªáu Nhi·ªÅu Ngu·ªìn")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("1. Nh·∫≠p D·ªØ Li·ªáu Th·ªß C√¥ng")
            input_method = st.radio(
                "Ch·ªçn ph∆∞∆°ng th·ª©c nh·∫≠p:",
                ["Nh·∫≠p nhi·ªÅu s·ªë", "Nh·∫≠p t·ª´ng s·ªë"]
            )
            
            if input_method == "Nh·∫≠p nhi·ªÅu s·ªë":
                data_input = st.text_area(
                    "Nh·∫≠p c√°c s·ªë 5 ch·ªØ s·ªë (m·ªói s·ªë m·ªôt d√≤ng ho·∫∑c c√°ch nhau b·ªüi d·∫•u c√°ch/ph·∫©y):",
                    height=200,
                    value=st.session_state.raw_data,
                    placeholder="""12345
67890
54321
09876
13579"""
                )
                
                if st.button("X·ª≠ l√Ω d·ªØ li·ªáu", key="process_manual"):
                    numbers = parse_input_data(data_input)
                    if numbers:
                        st.session_state.data = pd.DataFrame({'number': numbers})
                        st.session_state.raw_data = data_input
                        st.success(f"‚úÖ ƒê√£ nh·∫≠p {len(numbers)} s·ªë h·ª£p l·ªá!")
                        if auto_analyze:
                            analyzer = LotteryAnalyzer(st.session_state.data)
                            st.session_state.analysis_results = analyzer.analyze_all()
                    else:
                        st.error("‚ùå Kh√¥ng t√¨m th·∫•y s·ªë h·ª£p l·ªá n√†o!")
            
            else:  # Nh·∫≠p t·ª´ng s·ªë
                single_number = st.text_input("Nh·∫≠p s·ªë 5 ch·ªØ s·ªë:", max_chars=5)
                if st.button("Th√™m s·ªë", key="add_single"):
                    if validate_lottery_number(single_number):
                        cleaned = clean_number_string(single_number)
                        new_df = pd.DataFrame({'number': [cleaned]})
                        st.session_state.data = pd.concat([st.session_state.data, new_df], ignore_index=True)
                        st.success(f"‚úÖ ƒê√£ th√™m s·ªë: {cleaned}")
                        if auto_analyze:
                            analyzer = LotteryAnalyzer(st.session_state.data)
                            st.session_state.analysis_results = analyzer.analyze_all()
                    else:
                        st.error("‚ùå S·ªë kh√¥ng h·ª£p l·ªá! Ph·∫£i ƒë√∫ng 5 ch·ªØ s·ªë.")
        
        with col2:
            st.subheader("2. Import File")
            file_type = st.selectbox("Ch·ªçn lo·∫°i file:", ["TXT", "CSV"])
            
            uploaded_file = st.file_uploader(
                f"Ch·ªçn file {file_type}",
                type=[file_type.lower()],
                key="file_upload"
            )
            
            if uploaded_file is not None:
                try:
                    if file_type == "TXT":
                        content = uploaded_file.read().decode('utf-8')
                        numbers = parse_input_data(content)
                    else:  # CSV
                        df = pd.read_csv(uploaded_file)
                        # T√¨m c·ªôt ch·ª©a s·ªë
                        number_col = None
                        for col in df.columns:
                            sample = df[col].iloc[0] if len(df) > 0 else ""
                            if isinstance(sample, str) and len(clean_number_string(sample)) == 5:
                                number_col = col
                                break
                        
                        if number_col:
                            numbers = [clean_number_string(str(x)) for x in df[number_col] if validate_lottery_number(str(x))]
                        else:
                            st.error("Kh√¥ng t√¨m th·∫•y c·ªôt ch·ª©a s·ªë 5 ch·ªØ s·ªë!")
                            numbers = []
                    
                    if numbers:
                        st.session_state.data = pd.DataFrame({'number': numbers})
                        st.success(f"‚úÖ ƒê√£ import {len(numbers)} s·ªë t·ª´ file!")
                        if auto_analyze:
                            analyzer = LotteryAnalyzer(st.session_state.data)
                            st.session_state.analysis_results = analyzer.analyze_all()
                    else:
                        st.error("Kh√¥ng t√¨m th·∫•y s·ªë h·ª£p l·ªá trong file!")
                        
                except Exception as e:
                    st.error(f"L·ªói khi ƒë·ªçc file: {str(e)}")
            
            st.subheader("3. T·∫£i D·ªØ Li·ªáu M·∫´u")
            if st.button("T·∫£i d·ªØ li·ªáu m·∫´u", key="load_sample"):
                sample_data = download_sample_data()
                numbers = parse_input_data(sample_data)
                st.session_state.data = pd.DataFrame({'number': numbers})
                st.session_state.raw_data = sample_data
                st.success(f"‚úÖ ƒê√£ t·∫£i {len(numbers)} s·ªë m·∫´u!")
                if auto_analyze:
                    analyzer = LotteryAnalyzer(st.session_state.data)
                    st.session_state.analysis_results = analyzer.analyze_all()
        
        # Hi·ªÉn th·ªã d·ªØ li·ªáu hi·ªán t·∫°i
        st.markdown("---")
        st.subheader("üìã D·ªØ Li·ªáu Hi·ªán T·∫°i")
        
        if not st.session_state.data.empty:
            # Hi·ªÉn th·ªã v·ªõi style ƒë∆°n gi·∫£n
            st.dataframe(
                st.session_state.data,
                column_config={
                    "number": st.column_config.TextColumn(
                        "S·ªë",
                        width="medium"
                    )
                },
                hide_index=True,
                use_container_width=True
            )
            
            # N√∫t x√≥a d·ªØ li·ªáu
            col_actions1, col_actions2, col_actions3 = st.columns(3)
            with col_actions1:
                if st.button("X√≥a t·∫•t c·∫£ d·ªØ li·ªáu", type="secondary"):
                    st.session_state.data = pd.DataFrame(columns=['number'])
                    st.session_state.analysis_results = None
                    st.rerun()
            
            with col_actions2:
                # Export TXT
                if st.button("Export TXT"):
                    txt_data = "\n".join(st.session_state.data['number'].tolist())
                    st.download_button(
                        label="T·∫£i xu·ªëng TXT",
                        data=txt_data,
                        file_name=f"lotobet_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain"
                    )
            
            with col_actions3:
                # Export CSV
                if st.button("Export CSV"):
                    csv_data = st.session_state.data.to_csv(index=False)
                    st.download_button(
                        label="T·∫£i xu·ªëng CSV",
                        data=csv_data,
                        file_name=f"lotobet_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
        else:
            st.info("üì≠ Ch∆∞a c√≥ d·ªØ li·ªáu. Vui l√≤ng nh·∫≠p d·ªØ li·ªáu ·ªü tr√™n.")
    
    # ========== TAB 2: QUICK ANALYSIS ==========
    with tab2:
        st.header("‚ö° Ph√¢n T√≠ch Nhanh")
        
        if st.session_state.data.empty:
            st.warning("‚è≥ Vui l√≤ng nh·∫≠p d·ªØ li·ªáu ·ªü Tab 1 tr∆∞·ªõc!")
        else:
            if st.button("üöÄ Ch·∫°y Ph√¢n T√≠ch Nhanh", type="primary") or st.session_state.analysis_results:
                if not st.session_state.analysis_results:
                    with st.spinner("ƒêang ph√¢n t√≠ch d·ªØ li·ªáu..."):
                        analyzer = LotteryAnalyzer(st.session_state.data)
                        st.session_state.analysis_results = analyzer.analyze_all()
                
                if st.session_state.analysis_results:
                    # T√¨m s·ªë c√≥ x√°c su·∫•t cao nh·∫•t
                    best_digit = max(
                        st.session_state.analysis_results.items(),
                        key=lambda x: x[1]['percentage']
                    )
                    
                    # Hi·ªÉn th·ªã k·∫øt qu·∫£ n·ªïi b·∫≠t
                    st.markdown("---")
                    col_result1, col_result2 = st.columns(2)
                    
                    with col_result1:
                        st.markdown("### üéØ S·ªê M·∫†NH NH·∫§T")
                        st.markdown(f"# **{best_digit[0]}**")
                        st.markdown(f"### {best_digit[1]['percentage']:.1f}%")
                        
                        # Hi·ªÉn th·ªã thanh ti·∫øn tr√¨nh
                        progress_value = best_digit[1]['percentage'] / 100
                        st.progress(progress_value)
                        
                        st.markdown(f"**Khuy·∫øn ngh·ªã:** {best_digit[1]['recommendation']}")
                    
                    with col_result2:
                        st.markdown("### üìà Chi Ti·∫øt X√°c Su·∫•t")
                        # Hi·ªÉn th·ªã top 3 s·ªë
                        sorted_results = sorted(
                            st.session_state.analysis_results.items(),
                            key=lambda x: x[1]['percentage'],
                            reverse=True
                        )[:3]
                        
                        for digit, info in sorted_results:
                            col_a, col_b = st.columns([1, 3])
                            with col_a:
                                st.markdown(f"### **{digit}**")
                            with col_b:
                                st.markdown(f"**{info['percentage']:.1f}%**")
                                st.progress(info['percentage'] / 100)
                    
                    # Gi·∫£i th√≠ch k·∫øt qu·∫£
                    st.markdown("---")
                    st.markdown("#### üìù Gi·∫£i Th√≠ch")
                    st.info(f"S·ªë **{best_digit[0]}** c√≥ x√°c su·∫•t xu·∫•t hi·ªán cao nh·∫•t ({best_digit[1]['percentage']:.1f}%) "
                           f"trong gi·∫£i ƒë·∫∑c bi·ªát 5 s·ªë k·ª≥ t·ªõi. "
                           f"Khuy·∫øn ngh·ªã: **{best_digit[1]['recommendation']}**")
                    
                    # L∆∞u √Ω
                    st.markdown("---")
                    st.caption("‚ö†Ô∏è **L∆∞u √Ω quan tr·ªçng:** ƒê√¢y l√† d·ª± ƒëo√°n d·ª±a tr√™n ph√¢n t√≠ch d·ªØ li·ªáu l·ªãch s·ª≠. "
                              "K·∫øt qu·∫£ kh√¥ng ƒë·∫£m b·∫£o 100% ch√≠nh x√°c.")
                else:
                    st.error("Kh√¥ng th·ªÉ ph√¢n t√≠ch d·ªØ li·ªáu. Vui l√≤ng ki·ªÉm tra l·∫°i d·ªØ li·ªáu ƒë·∫ßu v√†o.")
    
    # ========== TAB 3: DETAILED ANALYSIS ==========
    with tab3:
        st.header("üìä Ph√¢n T√≠ch Chi Ti·∫øt")
        
        if st.session_state.data.empty:
            st.warning("‚è≥ Vui l√≤ng nh·∫≠p d·ªØ li·ªáu ·ªü Tab 1 tr∆∞·ªõc!")
        else:
            if not st.session_state.analysis_results:
                if st.button("üìä Ch·∫°y Ph√¢n T√≠ch Chi Ti·∫øt", type="primary"):
                    with st.spinner("ƒêang ph√¢n t√≠ch chi ti·∫øt..."):
                        analyzer = LotteryAnalyzer(st.session_state.data)
                        st.session_state.analysis_results = analyzer.analyze_all()
                    st.rerun()
            
            if st.session_state.analysis_results:
                # T·∫°o DataFrame cho b·∫£ng k·∫øt qu·∫£
                analysis_df = pd.DataFrame([
                    {
                        'S·ªê': digit,
                        '% XU·∫§T HI·ªÜN': f"{info['percentage']:.1f}%",
                        'KHUY·∫æN NGH·ªä': info['recommendation'],
                        'ƒêI·ªÇM CHI TI·∫æT': info['details']
                    }
                    for digit, info in st.session_state.analysis_results.items()
                ])
                
                # S·∫Øp x·∫øp theo ph·∫ßn trƒÉm gi·∫£m d·∫ßn
                analysis_df['SORT_KEY'] = analysis_df['% XU·∫§T HI·ªÜN'].str.replace('%', '').astype(float)
                analysis_df = analysis_df.sort_values('SORT_KEY', ascending=False).drop('SORT_KEY', axis=1)
                
                # Hi·ªÉn th·ªã b·∫£ng
                st.dataframe(
                    analysis_df[['S·ªê', '% XU·∫§T HI·ªÜN', 'KHUY·∫æN NGH·ªä']],
                    hide_index=True,
                    use_container_width=True,
                    column_config={
                        "S·ªê": st.column_config.TextColumn(width="small"),
                        "% XU·∫§T HI·ªÜN": st.column_config.ProgressColumn(
                            "% XU·∫§T HI·ªÜN",
                            format="%.1f%%",
                            min_value=0,
                            max_value=100,
                            width="medium"
                        ),
                        "KHUY·∫æN NGH·ªä": st.column_config.TextColumn(width="small")
                    }
                )
                
                # Visualizations
                st.markdown("---")
                st.subheader("üìà Bi·ªÉu ƒê·ªì Ph√¢n T√≠ch")
                
                col_viz1, col_viz2 = st.columns(2)
                
                with col_viz1:
                    # Bar chart
                    chart_data = pd.DataFrame([
                        {'S·ªë': digit, 'X√°c su·∫•t': info['percentage']}
                        for digit, info in st.session_state.analysis_results.items()
                    ])
                    chart_data = chart_data.sort_values('X√°c su·∫•t', ascending=False)
                    
                    fig, ax = plt.subplots(figsize=(10, 6))
                    bars = ax.bar(chart_data['S·ªë'], chart_data['X√°c su·∫•t'], 
                                 color=['#4CAF50' if x > 50 else '#F44336' for x in chart_data['X√°c su·∫•t']])
                    ax.set_xlabel('S·ªë')
                    ax.set_ylabel('X√°c su·∫•t (%)')
                    ax.set_title('X√°c su·∫•t xu·∫•t hi·ªán c·ªßa c√°c s·ªë')
                    ax.axhline(y=50, color='r', linestyle='--', alpha=0.5, label='Ng∆∞·ª°ng 50%')
                    ax.legend()
                    
                    # Th√™m gi√° tr·ªã tr√™n c√°c c·ªôt
                    for bar in bars:
                        height = bar.get_height()
                        ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                                f'{height:.1f}%', ha='center', va='bottom', fontsize=9)
                    
                    st.pyplot(fig)
                
                with col_viz2:
                    # Heatmap details
                    details_df = pd.DataFrame([
                        {**info['details'], 'S·ªë': digit}
                        for digit, info in st.session_state.analysis_results.items()
                    ]).set_index('S·ªë')
                    
                    fig2, ax2 = plt.subplots(figsize=(10, 6))
                    sns.heatmap(details_df, annot=True, fmt='.2f', cmap='YlOrRd', ax=ax2)
                    ax2.set_title('Chi ti·∫øt ƒëi·ªÉm s·ªë t·ª´ng thu·∫≠t to√°n')
                    st.pyplot(fig2)
                
                # T·∫£i xu·ªëng k·∫øt qu·∫£
                st.markdown("---")
                st.subheader("üì• T·∫£i Xu·ªëng K·∫øt Qu·∫£")
                
                # Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·ªÉ export
                export_df = pd.DataFrame([
                    {
                        'S·ªë': digit,
                        'X√°c_su·∫•t_%': info['percentage'],
                        'Khuy·∫øn_ngh·ªã': info['recommendation'],
                        'ƒêi·ªÉm_t·∫ßn_su·∫•t': info['details']['frequency'],
                        'ƒêi·ªÉm_ƒë·ªô_tr·ªÖ': info['details']['delay'],
                        'ƒêi·ªÉm_chu_k·ª≥': info['details']['cycle'],
                        'ƒêi·ªÉm_ƒë·ªìng_xu·∫•t_hi·ªán': info['details']['cooccurrence'],
                        'ƒêi·ªÉm_pattern': info['details']['pattern'],
                        'ƒêi·ªÉm_entropy': info['details']['entropy'],
                        'ƒêi·ªÉm_lo·∫°i_nhi·ªÖu': info['details']['noise']
                    }
                    for digit, info in st.session_state.analysis_results.items()
                ])
                
                col_export1, col_export2 = st.columns(2)
                
                with col_export1:
                    # Export CSV
                    csv_export = export_df.to_csv(index=False)
                    st.download_button(
                        label="üìä T·∫£i k·∫øt qu·∫£ CSV",
                        data=csv_export,
                        file_name=f"lotobet_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                        key="download_csv"
                    )
                
                with col_export2:
                    # Export JSON
                    json_export = export_df.to_json(orient='records', force_ascii=False)
                    st.download_button(
                        label="üìÑ T·∫£i k·∫øt qu·∫£ JSON",
                        data=json_export,
                        file_name=f"lotobet_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json",
                        key="download_json"
                    )
                
                # Th·ªëng k√™ h·ªá th·ªëng
                st.markdown("---")
                with st.expander("üìä Th·ªëng K√™ H·ªá Th·ªëng"):
                    col_stats1, col_stats2, col_stats3 = st.columns(3)
                    
                    with col_stats1:
                        st.metric("T·ªïng s·ªë d·ªØ li·ªáu", len(st.session_state.data))
                    
                    with col_stats2:
                        avg_prob = np.mean([info['percentage'] for info in st.session_state.analysis_results.values()])
                        st.metric("X√°c su·∫•t trung b√¨nh", f"{avg_prob:.1f}%")
                    
                    with col_stats3:
                        recommend_count = sum(1 for info in st.session_state.analysis_results.values() 
                                            if info['recommendation'] == 'ƒê√ÅNH')
                        st.metric("S·ªë ƒë∆∞·ª£c khuy·∫øn ngh·ªã", recommend_count)
            
            else:
                st.info("üëà Nh·∫•n n√∫t 'Ch·∫°y Ph√¢n T√≠ch Chi Ti·∫øt' ƒë·ªÉ xem k·∫øt qu·∫£")

    # Footer
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center; color: gray;'>
        <p>LOTOBET AI v1.0 | S·ª≠ d·ª•ng ph√¢n t√≠ch ƒëa thu·∫≠t to√°n | Phi√™n b·∫£n d√†nh cho mobile</p>
        <p>‚ö†Ô∏è Tool h·ªó tr·ª£ ph√¢n t√≠ch, kh√¥ng ƒë·∫£m b·∫£o k·∫øt qu·∫£ 100% ch√≠nh x√°c</p>
        </div>
        """,
        unsafe_allow_html=True
    )

# ==================== MAIN EXECUTION ====================
if __name__ == "__main__":
    main()
