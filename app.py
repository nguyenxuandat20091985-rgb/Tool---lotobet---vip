import streamlit as st
import pandas as pd
import numpy as np
from collections import Counter, defaultdict
from itertools import combinations, permutations
from datetime import datetime, timedelta
import os
import random
import json
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# ================= CONFIG =================
st.set_page_config(
    page_title="NUMCORE AI PRO",
    layout="wide",
    page_icon="üéØ"
)

DATA_FILE = "numcore_data.csv"
AI_CONFIG_FILE = "ai_config.json"

# ================= ADVANCED AI ENHANCEMENTS =================
class AdvancedAI:
    def __init__(self):
        self.pattern_memory = defaultdict(list)
        self.history_window = 25
        self.position_analysis = {i: Counter() for i in range(5)}
        self.number_relations = defaultdict(Counter)
        self.load_config()
    
    def load_config(self):
        """Load AI configuration"""
        default_config = {
            "weight_recent": 0.5,
            "weight_frequency": 0.25,
            "weight_position": 0.15,
            "weight_pattern": 0.1,
            "avoid_recent_count": 4,
            "hot_number_threshold": 0.12,
            "position_weight_factor": 0.8,
            "relation_weight": 0.3
        }
        
        if os.path.exists(AI_CONFIG_FILE):
            with open(AI_CONFIG_FILE, 'r') as f:
                self.config = {**default_config, **json.load(f)}
        else:
            self.config = default_config
    
    def analyze_position_patterns(self, numbers_history):
        """Analyze which numbers appear in which positions"""
        position_stats = {i: Counter() for i in range(5)}
        
        for numbers in numbers_history:
            if len(numbers) == 5:
                for pos, num in enumerate(numbers):
                    position_stats[pos][num] += 1
        
        return position_stats
    
    def analyze_relations(self, numbers_history):
        """Analyze relations between numbers in same draw"""
        relations = defaultdict(Counter)
        
        for numbers in numbers_history:
            if len(numbers) == 5:
                for i in range(5):
                    for j in range(i+1, 5):
                        pair = tuple(sorted([numbers[i], numbers[j]]))
                        relations[numbers[i]][numbers[j]] += 1
                        relations[numbers[j]][numbers[i]] += 1
        
        return relations
    
    def calculate_position_scores(self, numbers_history):
        """Calculate position-based scores for each number"""
        position_stats = self.analyze_position_patterns(numbers_history)
        position_scores = {}
        
        for num in range(10):
            scores = []
            for pos in range(5):
                total_in_pos = sum(position_stats[pos].values())
                if total_in_pos > 0:
                    freq = position_stats[pos][num] / total_in_pos
                    # Weight by position importance
                    pos_weight = 1.0 - (abs(pos - 2) * 0.2)  # Center positions get more weight
                    scores.append(freq * pos_weight)
            
            if scores:
                position_scores[num] = np.mean(scores) * self.config['position_weight_factor']
            else:
                position_scores[num] = 0
        
        return position_scores
    
    def calculate_relation_scores(self, numbers_history, hot_numbers):
        """Calculate scores based on number relations"""
        relations = self.analyze_relations(numbers_history)
        relation_scores = {}
        
        for num in range(10):
            if num in relations:
                # Check relations with hot numbers
                total_relations = 0
                strong_relations = 0
                
                for hot_num in hot_numbers[:3]:
                    if hot_num in relations[num]:
                        total_relations += relations[num][hot_num]
                        if relations[num][hot_num] > 0:
                            strong_relations += 1
                
                if total_relations > 0:
                    relation_scores[num] = (strong_relations / len(hot_numbers[:3])) * self.config['relation_weight']
                else:
                    relation_scores[num] = 0
            else:
                relation_scores[num] = 0
        
        return relation_scores
    
    def predict_top_two_numbers(self, numbers_history, hot_numbers):
        """Predict top 2 numbers with highest probability"""
        if len(numbers_history) < 10:
            return [], {}
        
        # Calculate various scores
        trend_data = self.analyze_trends(numbers_history)
        position_scores = self.calculate_position_scores(numbers_history)
        relation_scores = self.calculate_relation_scores(numbers_history, hot_numbers)
        
        # Combine all scores
        candidate_scores = {}
        
        for num in range(10):
            # Skip numbers that are already hot (we want complementary numbers)
            if num in hot_numbers[:5]:
                continue
            
            total_score = 0
            
            # Frequency score
            freq_score = trend_data['frequencies'].get(num, 0)
            total_score += freq_score * self.config['weight_frequency']
            
            # Trend score
            trend_score = trend_data['trends'].get(num, 0)
            total_score += max(0, trend_score) * 0.5
            
            # Position score
            total_score += position_scores.get(num, 0)
            
            # Relation score
            total_score += relation_scores.get(num, 0)
            
            # Recent appearance penalty
            recent_appearance = any(num in nums for nums in numbers_history[-self.config['avoid_recent_count']:])
            if recent_appearance:
                total_score *= 0.7
            
            candidate_scores[num] = total_score
        
        # Get top 2 candidates
        top_candidates = sorted(candidate_scores.items(), key=lambda x: x[1], reverse=True)[:2]
        
        result = []
        details = {}
        
        for i, (num, score) in enumerate(top_candidates):
            result.append(num)
            
            # Calculate confidence level
            confidence = min(95, 60 + int(score * 100))
            
            details[num] = {
                'score': round(score, 3),
                'confidence': confidence,
                'position_strength': round(position_scores.get(num, 0), 3),
                'relation_strength': round(relation_scores.get(num, 0), 3)
            }
        
        return result, details
    
    def generate_combination_predictions(self, numbers_history, hot_numbers, top_two):
        """Generate combination A and B predictions"""
        if len(top_two) < 2:
            return {"A": "--", "B": "--"}
        
        # Strategy 1: Combine top two with hottest number
        combination_A = []
        if hot_numbers and len(hot_numbers) >= 1:
            combination_A = [top_two[0], top_two[1], hot_numbers[0]]
            combination_A.sort()
        
        # Strategy 2: Combine with position-favored numbers
        combination_B = []
        if len(hot_numbers) >= 3:
            # Find number with best position score that's not already used
            position_scores = self.calculate_position_scores(numbers_history)
            position_candidates = [(num, score) for num, score in position_scores.items() 
                                 if num not in combination_A and num not in top_two]
            
            if position_candidates:
                best_position_num = max(position_candidates, key=lambda x: x[1])[0]
                combination_B = [top_two[0], hot_numbers[1], best_position_num]
                combination_B.sort()
        
        return {
            "A": "".join(map(str, combination_A)) if combination_A else "--",
            "B": "".join(map(str, combination_B)) if combination_B else "--"
        }
    
    def analyze_trends(self, numbers_history, window=15):
        """Analyze number trends over time - ENHANCED"""
        if len(numbers_history) < window:
            return {'frequencies': {}, 'trends': {}, 'most_common': [], 'least_common': []}
        
        recent = numbers_history[-window:]
        all_nums = [n for sublist in recent for n in sublist]
        
        # Frequency analysis
        freq = Counter(all_nums)
        total = len(all_nums)
        
        # Enhanced trend analysis with multiple windows
        trends = {}
        trend_strength = {}
        
        for num in range(10):
            # Multiple time window analysis
            windows = [
                (len(numbers_history)//3, len(numbers_history)//3*2),
                (len(numbers_history)//4, len(numbers_history)//4*3),
                (max(0, len(numbers_history)-window), len(numbers_history))
            ]
            
            window_trends = []
            for start, end in windows:
                if end > start:
                    early = numbers_history[start:start+(end-start)//2]
                    late = numbers_history[start+(end-start)//2:end]
                    
                    early_count = sum(1 for nums in early for n in nums if n == num)
                    late_count = sum(1 for nums in late for n in nums if n == num)
                    
                    if early_count + late_count > 0:
                        trend_val = (late_count - early_count) / max(1, (early_count + late_count))
                        window_trends.append(trend_val)
            
            if window_trends:
                trends[num] = np.mean(window_trends)
                trend_strength[num] = np.std(window_trends)  # Consistency of trend
        
        return {
            'frequencies': {k: v/total for k, v in freq.items()},
            'trends': trends,
            'trend_strength': trend_strength,
            'most_common': freq.most_common(10),
            'least_common': freq.most_common()[:-11:-1]
        }
    
    def predict_exclusions(self, numbers_history, hot_numbers):
        """Enhanced exclusion prediction"""
        if len(numbers_history) < 8:
            return []
        
        exclusions = set()
        
        # Rule 1: Numbers that appeared too recently
        recent_window = min(5, len(numbers_history))
        for nums in numbers_history[-recent_window:]:
            exclusions.update(nums)
        
        # Rule 2: Cold numbers with negative trends
        trend_data = self.analyze_trends(numbers_history)
        for num, trend in trend_data['trends'].items():
            if trend < -0.3:  # Strong negative trend
                exclusions.add(num)
        
        # Rule 3: Numbers with poor position performance
        position_stats = self.analyze_position_patterns(numbers_history)
        for num in range(10):
            pos_performance = sum(position_stats[pos][num] for pos in range(5))
            if pos_performance == 0 and num in hot_numbers:
                exclusions.add(num)
        
        return list(exclusions)[:5]
    
    def analyze_advanced_patterns(self, numbers_history):
        """Advanced pattern analysis"""
        if len(numbers_history) < 15:
            return {}
        
        patterns = {
            'position_patterns': self.analyze_position_patterns(numbers_history),
            'digit_gaps': [],
            'sum_analysis': [],
            'parity_analysis': []
        }
        
        for nums in numbers_history[-15:]:
            if len(nums) == 5:
                # Digit gaps analysis
                gaps = [abs(nums[i] - nums[i+1]) for i in range(4)]
                patterns['digit_gaps'].extend(gaps)
                
                # Sum analysis
                patterns['sum_analysis'].append(sum(nums))
                
                # Parity analysis
                odd_count = sum(1 for n in nums if n % 2 == 1)
                patterns['parity_analysis'].append(odd_count)
        
        return patterns

# ================= DATA FUNCTIONS =================
def load_data():
    """Load historical data"""
    if not os.path.exists(DATA_FILE):
        return pd.DataFrame(columns=["time", "numbers", "source"])
    
    try:
        df = pd.read_csv(DATA_FILE)
        
        # Ensure required columns
        if "numbers" not in df.columns:
            if len(df.columns) > 0:
                df["numbers"] = df.iloc[:, -1].astype(str)
            else:
                df["numbers"] = ""
        
        if "time" not in df.columns:
            df["time"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        if "source" not in df.columns:
            df["source"] = "manual"
        
        df["numbers"] = df["numbers"].astype(str).str.strip()
        return df[["time", "numbers", "source"]]
    
    except Exception as e:
        st.error(f"L·ªói ƒë·ªçc d·ªØ li·ªáu: {e}")
        return pd.DataFrame(columns=["time", "numbers", "source"])

def save_data(values, source="manual"):
    """Save multiple entries with source tracking"""
    df = load_data()
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    rows = []
    for v in values:
        v_str = str(v).strip()
        if v_str.isdigit() and len(v_str) == 5:
            rows.append({
                "time": now, 
                "numbers": v_str,
                "source": source
            })
    
    if rows:
        new_df = pd.DataFrame(rows)
        df = pd.concat([df, new_df], ignore_index=True)
        
        # Remove duplicates
        df = df.drop_duplicates(subset=['numbers'], keep='first')
        
        # Sort by time
        df['time'] = pd.to_datetime(df['time'])
        df = df.sort_values('time', ascending=True)
        
        df.to_csv(DATA_FILE, index=False)
    
    return len(rows)

def parse_numbers(v):
    """Parse string to list of integers"""
    try:
        return [int(x) for x in str(v) if x.isdigit()][:5]
    except:
        return []

def get_statistics(df):
    """Calculate comprehensive statistics"""
    if df.empty:
        return {}
    
    all_numbers = []
    number_sequences = []
    
    for nums_str in df['numbers']:
        nums = parse_numbers(nums_str)
        if len(nums) == 5:
            all_numbers.extend(nums)
            number_sequences.append(nums)
    
    if not all_numbers:
        return {}
    
    counter = Counter(all_numbers)
    total = len(all_numbers)
    
    # Advanced statistics
    stats = {
        'total_draws': len(df),
        'total_digits': total,
        'frequency': dict(counter),
        'percentage': {k: f"{(v/total*100):.1f}%" for k, v in counter.items()},
        'most_common': counter.most_common(10),
        'least_common': counter.most_common()[:-11:-1],
        'hot_numbers': [n for n, c in counter.most_common(5)],
        'warm_numbers': [n for n, c in counter.most_common(10)[5:]],
        'cold_numbers': [n for n, c in counter.most_common()[:-6:-1]],
        'number_sequences': number_sequences
    }
    
    # Position analysis
    if number_sequences:
        position_stats = []
        for pos in range(5):
            pos_numbers = [seq[pos] for seq in number_sequences if len(seq) > pos]
            pos_counter = Counter(pos_numbers)
            position_stats.append(dict(pos_counter.most_common(5)))
        
        stats['position_stats'] = position_stats
    
    return stats

# ================= UI =================
def main():
    st.title("üéØ NUMCORE AI PRO")
    st.caption("Ph√¢n t√≠ch chuy√™n s√¢u 5 s·ªë - D·ª± ƒëo√°n th√¥ng minh - ƒê·ªô ch√≠nh x√°c cao")
    
    # Initialize Advanced AI
    ai = AdvancedAI()
    
    tab1, tab2, tab3, tab4 = st.tabs([
        "üì• Nh·∫≠p li·ªáu",
        "üéØ Ph√¢n t√≠ch AI N√¢ng cao",
        "üìä Th·ªëng k√™ chi ti·∫øt",
        "‚öôÔ∏è C·∫•u h√¨nh AI"
    ])
    
    # ============ TAB 1: DATA INPUT ============
    with tab1:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("üì• Nh·∫≠p d·ªØ li·ªáu h√†ng lo·∫°t")
            
            raw = st.text_area(
                "Nh·∫≠p nhi·ªÅu k·ª≥ (m·ªói d√≤ng 5 s·ªë)",
                height=200,
                placeholder="V√≠ d·ª•:\n12345\n67890\n54321\n...",
                help="M·ªói d√≤ng l√† m·ªôt k·ª≥ g·ªìm 5 ch·ªØ s·ªë ƒë·∫ßy ƒë·ªß",
                key="data_input"
            )
            
            if st.button("üíæ L∆∞u d·ªØ li·ªáu", type="primary", use_container_width=True, key="save_button"):
                if raw.strip():
                    lines = [x.strip() for x in raw.splitlines() if x.strip()]
                    saved = save_data(lines)
                    
                    if saved > 0:
                        st.success(f"‚úÖ ƒê√£ l∆∞u {saved} k·ª≥ h·ª£p l·ªá")
                        st.rerun()
                    else:
                        st.error("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá (c·∫ßn ƒë√∫ng 5 ch·ªØ s·ªë m·ªói d√≤ng)")
                else:
                    st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p d·ªØ li·ªáu tr∆∞·ªõc khi l∆∞u")
        
        with col2:
            st.subheader("üìÅ D·ªØ li·ªáu hi·ªán c√≥")
            df = load_data()
            
            if not df.empty:
                st.metric("T·ªïng s·ªë k·ª≥", len(df))
                
                try:
                    df['time'] = pd.to_datetime(df['time'])
                    latest = df['time'].max().strftime("%d/%m/%Y")
                    st.metric("D·ªØ li·ªáu m·ªõi nh·∫•t", latest)
                except:
                    st.metric("D·ªØ li·ªáu m·ªõi nh·∫•t", "N/A")
                
                with st.expander("Xem 5 k·ª≥ g·∫ßn nh·∫•t"):
                    st.dataframe(
                        df.tail(5)[['time', 'numbers']],
                        use_container_width=True,
                        hide_index=True
                    )
                
                if st.button("üîÑ L√†m m·ªõi", use_container_width=True, key="refresh_button"):
                    st.rerun()
            else:
                st.info("üì≠ Ch∆∞a c√≥ d·ªØ li·ªáu")
                st.caption("Nh·∫≠p d·ªØ li·ªáu ·ªü √¥ b√™n tr√°i ƒë·ªÉ b·∫Øt ƒë·∫ßu")
    
    # ============ TAB 2: ADVANCED AI ANALYSIS ============
    with tab2:
        df = load_data()
        
        if df.empty:
            st.warning("‚è≥ Vui l√≤ng nh·∫≠p d·ªØ li·ªáu tr∆∞·ªõc khi ph√¢n t√≠ch")
            st.info("Chuy·ªÉn sang tab 'üì• Nh·∫≠p li·ªáu' ƒë·ªÉ th√™m d·ªØ li·ªáu")
        else:
            # Prepare data
            stats = get_statistics(df)
            
            if 'number_sequences' not in stats:
                st.error("D·ªØ li·ªáu kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng 5 s·ªë")
                return
            
            numbers_history = stats['number_sequences']
            hot_numbers = stats.get('hot_numbers', [])
            
            if len(numbers_history) < 10:
                st.warning(f"‚ö†Ô∏è C·∫ßn √≠t nh·∫•t 10 k·ª≥ ƒë·ªÉ ph√¢n t√≠ch (hi·ªán c√≥: {len(numbers_history)})")
                return
            
            # Advanced AI Analysis
            st.subheader("üéØ PH√ÇN T√çCH AI CHUY√äN S√ÇU")
            
            # Predict top two numbers
            top_two, top_details = ai.predict_top_two_numbers(numbers_history, hot_numbers)
            
            # Generate combinations
            combinations = ai.generate_combination_predictions(numbers_history, hot_numbers, top_two)
            
            # Display results in a grid
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric(
                    "üî• S·ªë n√≥ng nh·∫•t",
                    f"{hot_numbers[0] if hot_numbers else '--'}",
                    delta=f"{stats['percentage'].get(hot_numbers[0], '0%') if hot_numbers else '0%'}"
                )
            
            with col2:
                if top_two and len(top_two) >= 1:
                    detail = top_details.get(top_two[0], {})
                    st.metric(
                        "ü•á D·ª± ƒëo√°n s·ªë 1",
                        str(top_two[0]),
                        delta=f"Tin c·∫≠y: {detail.get('confidence', 0)}%"
                    )
            
            with col3:
                if top_two and len(top_two) >= 2:
                    detail = top_details.get(top_two[1], {})
                    st.metric(
                        "ü•à D·ª± ƒëo√°n s·ªë 2",
                        str(top_two[1]),
                        delta=f"Tin c·∫≠y: {detail.get('confidence', 0)}%"
                    )
            
            with col4:
                st.metric(
                    "üìä ƒê·ªô ch√≠nh x√°c",
                    f"{min(85, 50 + len(numbers_history)//5)}%",
                    delta="D·ª±a tr√™n l·ªãch s·ª≠"
                )
            
            st.divider()
            
            # Combination predictions
            st.subheader("üî¢ D·ª∞ ƒêO√ÅN T·ªî H·ª¢P")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric(
                    "üéØ T·ªï h·ª£p A (∆Øu ti√™n cao)",
                    combinations['A'],
                    delta="K·∫øt h·ª£p s·ªë n√≥ng + d·ª± ƒëo√°n"
                )
                st.caption("Chi·∫øn l∆∞·ª£c: K·∫øt h·ª£p 2 s·ªë d·ª± ƒëo√°n v·ªõi s·ªë n√≥ng nh·∫•t")
            
            with col2:
                st.metric(
                    "üÖ±Ô∏è T·ªï h·ª£p B (D·ª± ph√≤ng)",
                    combinations['B'],
                    delta="K·∫øt h·ª£p v·ªã tr√≠ + xu h∆∞·ªõng"
                )
                st.caption("Chi·∫øn l∆∞·ª£c: K·∫øt h·ª£p v·ªõi s·ªë c√≥ v·ªã tr√≠ t·ªët nh·∫•t")
            
            st.divider()
            
            # Detailed analysis
            st.subheader("üìà PH√ÇN T√çCH CHI TI·∫æT")
            
            if top_two and top_details:
                details_col1, details_col2 = st.columns(2)
                
                with details_col1:
                    st.write("**üéØ Ph√¢n t√≠ch s·ªë d·ª± ƒëo√°n 1:**")
                    if top_two[0] in top_details:
                        detail = top_details[top_two[0]]
                        st.write(f"- **ƒêi·ªÉm s·ªë:** {detail['score']:.3f}")
                        st.write(f"- **ƒê·ªô tin c·∫≠y:** {detail['confidence']}%")
                        st.write(f"- **S·ª©c m·∫°nh v·ªã tr√≠:** {detail['position_strength']:.3f}")
                        st.write(f"- **Quan h·ªá s·ªë:** {detail['relation_strength']:.3f}")
                
                with details_col2:
                    st.write("**üéØ Ph√¢n t√≠ch s·ªë d·ª± ƒëo√°n 2:**")
                    if len(top_two) > 1 and top_two[1] in top_details:
                        detail = top_details[top_two[1]]
                        st.write(f"- **ƒêi·ªÉm s·ªë:** {detail['score']:.3f}")
                        st.write(f"- **ƒê·ªô tin c·∫≠y:** {detail['confidence']}%")
                        st.write(f"- **S·ª©c m·∫°nh v·ªã tr√≠:** {detail['position_strength']:.3f}")
                        st.write(f"- **Quan h·ªá s·ªë:** {detail['relation_strength']:.3f}")
            
            # Advanced patterns
            if len(numbers_history) >= 15:
                st.divider()
                st.subheader("üîç PH√ÇN T√çCH M·∫™U N√ÇNG CAO")
                
                patterns = ai.analyze_advanced_patterns(numbers_history)
                
                pattern_col1, pattern_col2 = st.columns(2)
                
                with pattern_col1:
                    st.write("**üìä Ph√¢n t√≠ch v·ªã tr√≠:**")
                    if 'position_patterns' in patterns:
                        for pos in range(5):
                            pos_name = ["ƒê·∫ßu", "Nh√¨", "Ba", "T∆∞", "NƒÉm"][pos]
                            top_pos_nums = patterns['position_patterns'][pos].most_common(3)
                            if top_pos_nums:
                                nums_str = ", ".join([f"{num}({count})" for num, count in top_pos_nums])
                                st.write(f"- **V·ªã tr√≠ {pos_name}:** {nums_str}")
                
                with pattern_col2:
                    st.write("**üìà Xu h∆∞·ªõng t·ªïng s·ªë:**")
                    if 'sum_analysis' in patterns and patterns['sum_analysis']:
                        avg_sum = np.mean(patterns['sum_analysis'])
                        common_sum = Counter(patterns['sum_analysis']).most_common(1)
                        st.write(f"- **T·ªïng trung b√¨nh:** {avg_sum:.1f}")
                        if common_sum:
                            st.write(f"- **T·ªïng ph·ªï bi·∫øn:** {common_sum[0][0]} ({common_sum[0][1]} l·∫ßn)")
            
            # Exclusion recommendations
            exclusions = ai.predict_exclusions(numbers_history, hot_numbers)
            if exclusions:
                st.divider()
                st.subheader("‚ö†Ô∏è KHUY·∫æN NGH·ªä TR√ÅNH")
                st.warning(f"S·ªë c·∫ßn th·∫≠n tr·ªçng: **{', '.join(map(str, exclusions[:5]))}**")
                st.caption("L√Ω do: Xu·∫•t hi·ªán g·∫ßn ƒë√¢y / Xu h∆∞·ªõng gi·∫£m / V·ªã tr√≠ y·∫øu")
    
    # ============ TAB 3: DETAILED STATISTICS ============
    with tab3:
        df = load_data()
        
        if not df.empty:
            stats = get_statistics(df)
            
            # Overview
            st.subheader("üìä T·ªîNG QUAN TH·ªêNG K√ä")
            
            overview_col1, overview_col2, overview_col3 = st.columns(3)
            
            with overview_col1:
                st.metric("T·ªïng s·ªë k·ª≥", stats['total_draws'])
                st.metric("T·ªïng s·ªë digit", stats['total_digits'])
            
            with overview_col2:
                if 'avg_draws_per_day' in stats:
                    st.metric("K·ª≥/ng√†y", f"{stats['avg_draws_per_day']:.1f}")
                
                hot_num = stats['hot_numbers'][0] if stats['hot_numbers'] else "--"
                hot_percent = stats['percentage'].get(hot_num, "0%")
                st.metric("S·ªë n√≥ng nh·∫•t", f"{hot_num} ({hot_percent})")
            
            with overview_col3:
                cold_num = stats['cold_numbers'][0] if stats['cold_numbers'] else "--"
                cold_percent = stats['percentage'].get(cold_num, "0%")
                st.metric("S·ªë l·∫°nh nh·∫•t", f"{cold_num} ({cold_percent})")
                
                coverage = len(stats['frequency']) / 10 * 100
                st.metric("ƒê·ªô ph·ªß s·ªë", f"{coverage:.1f}%")
            
            st.divider()
            
            # Hot and Cold numbers
            st.subheader("üî• S·ªê N√ìNG & ‚ùÑÔ∏è S·ªê L·∫†NH")
            
            hot_col, cold_col = st.columns(2)
            
            with hot_col:
                st.write("**Top 5 s·ªë n√≥ng:**")
                for i, (num, count) in enumerate(stats['most_common'][:5], 1):
                    percent = stats['percentage'].get(num, "0%")
                    st.write(f"{i}. **{num}** - {count} l·∫ßn ({percent})")
            
            with cold_col:
                st.write("**Top 5 s·ªë l·∫°nh:**")
                for i, (num, count) in enumerate(stats['least_common'][:5], 1):
                    percent = stats['percentage'].get(num, "0%")
                    st.write(f"{i}. **{num}** - {count} l·∫ßn ({percent})")
            
            # Position analysis
            if 'position_stats' in stats:
                st.divider()
                st.subheader("üéØ PH√ÇN T√çCH V·ªä TR√ç")
                
                pos_cols = st.columns(5)
                position_names = ["ƒê·∫ßu", "Nh√¨", "Ba", "T∆∞", "NƒÉm"]
                
                for idx, pos_col in enumerate(pos_cols):
                    with pos_col:
                        st.write(f"**V·ªã tr√≠ {position_names[idx]}:**")
                        if idx < len(stats['position_stats']):
                            for num, count in stats['position_stats'][idx].items():
                                st.write(f"{num}: {count} l·∫ßn")
            
            # Frequency chart
            st.divider()
            st.subheader("üìà BI·ªÇU ƒê·ªí T·∫¶N SU·∫§T")
            
            if stats['frequency']:
                freq_df = pd.DataFrame.from_dict(stats['frequency'], orient='index', columns=['count'])
                freq_df = freq_df.sort_values('count', ascending=True)  # Sort for better visualization
                st.bar_chart(freq_df)
            
            # Recent data
            st.divider()
            st.subheader("üìã D·ªÆ LI·ªÜU G·∫¶N ƒê√ÇY")
            
            display_df = df.tail(10).copy()
            if 'time' in display_df.columns:
                try:
                    display_df['time'] = pd.to_datetime(display_df['time']).dt.strftime('%d/%m/%Y %H:%M')
                except:
                    pass
            
            st.dataframe(
                display_df[['time', 'numbers']],
                use_container_width=True,
                hide_index=True,
                column_config={
                    "time": "Th·ªùi gian",
                    "numbers": "S·ªë"
                }
            )
        else:
            st.info("üì≠ Ch∆∞a c√≥ d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã th·ªëng k√™")
    
    # ============ TAB 4: AI CONFIGURATION ============
    with tab4:
        st.subheader("‚öôÔ∏è C·∫§U H√åNH AI N√ÇNG CAO")
        
        ai.load_config()
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**üìä Tr·ªçng s·ªë ph√¢n t√≠ch:**")
            weight_recent = st.slider(
                "Tr·ªçng s·ªë d·ªØ li·ªáu g·∫ßn ƒë√¢y",
                0.1, 0.8, float(ai.config.get('weight_recent', 0.5)), 0.05,
                help="·∫¢nh h∆∞·ªüng c·ªßa c√°c k·ª≥ g·∫ßn nh·∫•t"
            )
            
            weight_frequency = st.slider(
                "Tr·ªçng s·ªë t·∫ßn su·∫•t",
                0.1, 0.5, float(ai.config.get('weight_frequency', 0.25)), 0.05,
                help="·∫¢nh h∆∞·ªüng c·ªßa t·∫ßn su·∫•t xu·∫•t hi·ªán"
            )
            
            weight_position = st.slider(
                "Tr·ªçng s·ªë v·ªã tr√≠",
                0.05, 0.3, float(ai.config.get('weight_position', 0.15)), 0.05,
                help="·∫¢nh h∆∞·ªüng c·ªßa v·ªã tr√≠ s·ªë"
            )
        
        with col2:
            st.write("**üéØ Ng∆∞·ª°ng ph√¢n t√≠ch:**")
            avoid_recent = st.slider(
                "Tr√°nh s·ªë tr√πng (k·ª≥)",
                2, 8, int(ai.config.get('avoid_recent_count', 4)), 1,
                help="S·ªë k·ª≥ g·∫ßn nh·∫•t ƒë·ªÉ tr√°nh tr√πng s·ªë"
            )
            
            hot_threshold = st.slider(
                "Ng∆∞·ª°ng s·ªë n√≥ng (%)",
                8, 25, int(ai.config.get('hot_number_threshold', 0.12) * 100), 1,
                help="T·ªâ l·ªá xu·∫•t hi·ªán t·ªëi thi·ªÉu ƒë·ªÉ coi l√† s·ªë n√≥ng"
            ) / 100
            
            position_weight = st.slider(
                "·∫¢nh h∆∞·ªüng v·ªã tr√≠",
                0.5, 1.0, float(ai.config.get('position_weight_factor', 0.8)), 0.1,
                help="ƒê·ªô ·∫£nh h∆∞·ªüng c·ªßa ph√¢n t√≠ch v·ªã tr√≠"
            )
        
        if st.button("üíæ L∆∞u c·∫•u h√¨nh AI", type="primary", use_container_width=True):
            config = {
                "weight_recent": weight_recent,
                "weight_frequency": weight_frequency,
                "weight_position": weight_position,
                "weight_pattern": ai.config.get('weight_pattern', 0.1),
                "avoid_recent_count": avoid_recent,
                "hot_number_threshold": hot_threshold,
                "position_weight_factor": position_weight,
                "relation_weight": ai.config.get('relation_weight', 0.3)
            }
            
            try:
                with open(AI_CONFIG_FILE, 'w') as f:
                    json.dump(config, f, indent=2)
                ai.config = config
                
                st.success("‚úÖ ƒê√£ l∆∞u c·∫•u h√¨nh AI n√¢ng cao")
                st.rerun()
            except Exception as e:
                st.error(f"‚ùå L·ªói khi l∆∞u c·∫•u h√¨nh: {e}")
        
        st.divider()
        
        st.subheader("üîÑ QU·∫¢N L√ù D·ªÆ LI·ªÜU")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üóëÔ∏è X√≥a to√†n b·ªô d·ªØ li·ªáu", use_container_width=True, type="secondary"):
                if os.path.exists(DATA_FILE):
                    os.remove(DATA_FILE)
                    st.success("‚úÖ ƒê√£ x√≥a to√†n b·ªô d·ªØ li·ªáu")
                    st.rerun()
        
        with col2:
            if st.button("üì• Xu·∫•t d·ªØ li·ªáu", use_container_width=True):
                df = load_data()
                if not df.empty:
                    csv = df.to_csv(index=False)
                    st.download_button(
                        label="üìÑ T·∫£i file CSV",
                        data=csv,
                        file_name=f"numcore_pro_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                        use_container_width=True
                    )
                else:
                    st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ xu·∫•t")
    
    # ============ FOOTER ============
    st.divider()
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        df_count = len(load_data())
        st.caption(f"üìä D·ªØ li·ªáu: {df_count} k·ª≥")
    
    with col2:
        st.caption("ü§ñ AI: Advanced Pattern Recognition")
    
    with col3:
        st.caption("NUMCORE AI PRO v8.0 ‚Äì Ph√¢n t√≠ch chuy√™n s√¢u 5 s·ªë")

if __name__ == "__main__":
    main()
